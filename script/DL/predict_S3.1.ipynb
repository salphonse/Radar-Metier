{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca3893c",
   "metadata": {},
   "source": [
    "Model avec faux profils fait sur la base des codes romes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563af2f",
   "metadata": {},
   "source": [
    "Importations et S3 au début\n",
    "Modèle Transformer clair\n",
    "Fonctions utilitaires S3 centralisées\n",
    "Génération et upload des faux profils\n",
    "Chargement des modèles et des profils\n",
    "Fonction de prédiction hybride\n",
    "Boucle de prédiction lisible avec affichage complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00fabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées\n",
      "Debug ON\n",
      "Environment data: \n",
      "S3_ENDPOINT_URL: https://bhckzdwrhhfaxbidmwpm.supabase.co/storage/v1/s3 \n",
      "S3_ACCESS_KEY_ID (len): 32 bytes \n",
      "S3_SECRET_ACCESS_KEY (len): 64 bytes \n",
      "S3_REGION: eu-west-3\n",
      "Modèle Transformer défini\n",
      "Fichier 'df_competence_rome_eda_v2.csv' chargé depuis 'dlhybride'\n",
      "Fichier 'fake_profiles.csv' uploadé dans 'dlhybride'\n",
      "Modèle 'modele_epoch4000.pkl' chargé depuis S3 : <class '__main__.JobProfileTransformer'>\n",
      "Fichier 'fake_profiles.csv' chargé et nettoyé depuis 'dlhybride'\n",
      "============================================================\n",
      "Profil 1 → compétences (24):\n",
      " • 117585 - Contrôler les conditions de stockage des produits\n",
      " • 404877 - Optimiser l'utilisation des ressources en eau\n",
      " • 482836 - Assurer la traçabilité des produits\n",
      " • 123046 - Surveiller l'état d'une plantation\n",
      " • 482927 - Assurer le suivi des commandes et la gestion des stocks\n",
      " • 483520 - Appliquer les normes d'hygiène et de sécurité alimentaire\n",
      " • 503014 - Sélectionner et appliquer des engrais organiques\n",
      " • 100256 - Dispenser les soins préventifs ou curatifs aux animaux\n",
      " • 501439 - Optimiser la gestion de la trésorerie\n",
      " • 487242 - Evaluer les coûts de production et définir les prix de vente\n",
      " • 404009 - Gérer l'alimentation quotidienne des animaux\n",
      " • 489754 - Appliquer les éco-gestes dans sa pratique (eau, énergie, produits, ...)\n",
      " • 483454 - Evaluer les impacts des changements climatiques\n",
      " • 489565 - Veiller au respect des réglementations techniques et environnementales\n",
      " • 487245 - Etablir des partenariats avec des distributeurs\n",
      " • 117548 - Stocker un produit\n",
      " • 404011 - Entretenir un système d'irrigation et d'arrosage\n",
      " • 482805 - Agir rapidement en cas d'urgence médicale pour les animaux\n",
      " • 122573 - Planifier une opération de semis, de traitement ou de récolte sur un site d'exploitation\n",
      " • 485707 - Contrôler le confort des installations pour les animaux\n",
      " • 123081 - Renseigner un registre d'élevage\n",
      " • 504800 - Négocier les contrats de vente des produits agricoles\n",
      " • 123016 - Transformer un produit de l'élevage\n",
      " • 125527 - Effectuer des opérations agricoles (semis, récoltes)\n",
      "\n",
      "Métier attendu : A1416 - Exploitant / Exploitante agricole\n",
      "\n",
      "Top-3 métiers proposés :\n",
      "A1416 - Exploitant / Exploitante agricole - 83.4% | corrélation = 24 compétences\n",
      "   Compétences en commun :\n",
      "     • 100256 - Dispenser les soins préventifs ou curatifs aux animaux\n",
      "     • 117548 - Stocker un produit\n",
      "     • 117585 - Contrôler les conditions de stockage des produits\n",
      "     • 122573 - Planifier une opération de semis, de traitement ou de récolte sur un site d'exploitation\n",
      "     • 123016 - Transformer un produit de l'élevage\n",
      "     • 123046 - Surveiller l'état d'une plantation\n",
      "     • 123081 - Renseigner un registre d'élevage\n",
      "     • 125527 - Effectuer des opérations agricoles (semis, récoltes)\n",
      "     • 404009 - Gérer l'alimentation quotidienne des animaux\n",
      "     • 404011 - Entretenir un système d'irrigation et d'arrosage\n",
      "     • 404877 - Optimiser l'utilisation des ressources en eau\n",
      "     • 482805 - Agir rapidement en cas d'urgence médicale pour les animaux\n",
      "     • 482836 - Assurer la traçabilité des produits\n",
      "     • 482927 - Assurer le suivi des commandes et la gestion des stocks\n",
      "     • 483454 - Evaluer les impacts des changements climatiques\n",
      "     • 483520 - Appliquer les normes d'hygiène et de sécurité alimentaire\n",
      "     • 485707 - Contrôler le confort des installations pour les animaux\n",
      "     • 487242 - Evaluer les coûts de production et définir les prix de vente\n",
      "     • 487245 - Etablir des partenariats avec des distributeurs\n",
      "     • 489565 - Veiller au respect des réglementations techniques et environnementales\n",
      "     • 489754 - Appliquer les éco-gestes dans sa pratique (eau, énergie, produits, ...)\n",
      "     • 501439 - Optimiser la gestion de la trésorerie\n",
      "     • 503014 - Sélectionner et appliquer des engrais organiques\n",
      "     • 504800 - Négocier les contrats de vente des produits agricoles\n",
      "A1407 - Eleveur / Eleveuse de bovins - 26.4% | corrélation = 8 compétences\n",
      "   Compétences en commun :\n",
      "     • 100256 - Dispenser les soins préventifs ou curatifs aux animaux\n",
      "     • 117548 - Stocker un produit\n",
      "     • 123016 - Transformer un produit de l'élevage\n",
      "     • 123081 - Renseigner un registre d'élevage\n",
      "     • 125527 - Effectuer des opérations agricoles (semis, récoltes)\n",
      "     • 482836 - Assurer la traçabilité des produits\n",
      "     • 487242 - Evaluer les coûts de production et définir les prix de vente\n",
      "     • 487245 - Etablir des partenariats avec des distributeurs\n",
      "A1437 - Champignonniste - 18.7% | corrélation = 5 compétences\n",
      "   Compétences en commun :\n",
      "     • 117548 - Stocker un produit\n",
      "     • 117585 - Contrôler les conditions de stockage des produits\n",
      "     • 122573 - Planifier une opération de semis, de traitement ou de récolte sur un site d'exploitation\n",
      "     • 123046 - Surveiller l'état d'une plantation\n",
      "     • 487245 - Etablir des partenariats avec des distributeurs\n",
      "============================================================\n",
      "Profil 2 → compétences (6):\n",
      " • 483191 - Analyser les données de vente pour optimiser les stratégies\n",
      " • 121759 - Effectuer une démonstration devant un client ou un public\n",
      " • 485622 - Mettre en place des stratégies de vente\n",
      " • 485071 - Assurer la conformité des pratiques commerciales avec la réglementation\n",
      " • 400752 - Mettre en place des indicateurs de performance technique\n",
      " • 482132 - Collaborer avec d'autres départements pour aligner les objectifs\n",
      "\n",
      "Métier attendu : D1402 - Commercial / Commerciale grands comptes et entreprises\n",
      "\n",
      "Top-3 métiers proposés :\n",
      "D1402 - Commercial / Commerciale grands comptes et entreprises - 74.7% | corrélation = 6 compétences\n",
      "   Compétences en commun :\n",
      "     • 121759 - Effectuer une démonstration devant un client ou un public\n",
      "     • 400752 - Mettre en place des indicateurs de performance technique\n",
      "     • 482132 - Collaborer avec d'autres départements pour aligner les objectifs\n",
      "     • 483191 - Analyser les données de vente pour optimiser les stratégies\n",
      "     • 485071 - Assurer la conformité des pratiques commerciales avec la réglementation\n",
      "     • 485622 - Mettre en place des stratégies de vente\n",
      "D1401 - Assistant commercial / Assistante commerciale - 32.6% | corrélation = 2 compétences\n",
      "   Compétences en commun :\n",
      "     • 485071 - Assurer la conformité des pratiques commerciales avec la réglementation\n",
      "     • 485622 - Mettre en place des stratégies de vente\n",
      "\n",
      "Prédictions terminées\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1. Importation des bibliothèques\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import io\n",
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "print(\"Bibliothèques importées\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Connexion à Supabase via API S3-compatible\n",
    "# ---------------------------\n",
    "if not load_dotenv('.env'):\n",
    "    print(\"Load env from alternative path\")\n",
    "    load_dotenv('.env')\n",
    "\n",
    "if __debug__:\n",
    "    print('Debug ON')\n",
    "    print(\n",
    "        \"Environment data:\",\n",
    "        \"\\nS3_ENDPOINT_URL:\", os.getenv(\"S3_ENDPOINT_URL\"),\n",
    "        \"\\nS3_ACCESS_KEY_ID (len):\", len(os.getenv(\"S3_ACCESS_KEY_ID\", \"\")), \"bytes\",\n",
    "        \"\\nS3_SECRET_ACCESS_KEY (len):\", len(os.getenv(\"S3_SECRET_ACCESS_KEY\", \"\")), \"bytes\",\n",
    "        \"\\nS3_REGION:\", os.getenv(\"S3_REGION\")\n",
    "    )\n",
    "\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        service_name='s3',\n",
    "        region_name=os.getenv(\"S3_REGION\"),\n",
    "        endpoint_url=os.getenv(\"S3_ENDPOINT_URL\"),\n",
    "        aws_access_key_id=os.getenv(\"S3_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key=os.getenv(\"S3_SECRET_ACCESS_KEY\")\n",
    "    )\n",
    "except Exception as ex:\n",
    "    print(\"Erreur création client S3 :\", ex)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Définition du modèle Transformer\n",
    "# ---------------------------\n",
    "class JobProfileTransformer(nn.Module):\n",
    "    def __init__(self, n_skills, n_jobs, emb_dim=64, n_heads=4, n_layers=2, max_len=88):\n",
    "        super().__init__()\n",
    "        self.skill_emb = nn.Embedding(n_skills, emb_dim)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=256,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.job_emb = nn.Embedding(n_jobs, emb_dim)\n",
    "\n",
    "    def encode_profile(self, skills, weights=None):\n",
    "        batch_size, seq_len = skills.shape\n",
    "        if seq_len > self.pos_emb.size(1):\n",
    "            pos_emb = self.pos_emb.repeat(1, math.ceil(seq_len / self.pos_emb.size(1)), 1)[:, :seq_len, :]\n",
    "        else:\n",
    "            pos_emb = self.pos_emb[:, :seq_len, :]\n",
    "        skills_emb = self.skill_emb(skills) + pos_emb\n",
    "        if weights is not None:\n",
    "            skills_emb = skills_emb * weights.unsqueeze(-1)\n",
    "        mask = (skills == 0)\n",
    "        v = self.encoder(skills_emb, src_key_padding_mask=mask)\n",
    "        v = v.mean(dim=1)\n",
    "        return F.normalize(v, dim=1)\n",
    "\n",
    "    def encode_job(self, job_ids):\n",
    "        v = self.job_emb(job_ids)\n",
    "        return F.normalize(v, dim=1)\n",
    "\n",
    "print(\"Modèle Transformer défini\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Fonctions utilitaires S3\n",
    "# ---------------------------\n",
    "def read_csv_from_s3(file_name, bucket_name=\"dlhybride\"):\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "        df = pd.read_csv(io.BytesIO(response[\"Body\"].read()), encoding=\"utf-8\", dtype=str)\n",
    "        print(f\"Fichier '{file_name}' chargé depuis '{bucket_name}'\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture '{file_name}' depuis '{bucket_name}':\", e)\n",
    "        return None\n",
    "\n",
    "def upload_df_to_s3(df, file_name=\"fake_profiles.csv\", bucket_name=\"dlhybride\"):\n",
    "    try:\n",
    "        csv_buffer = io.StringIO()\n",
    "        df.to_csv(csv_buffer, index=False, encoding=\"utf-8\")\n",
    "        file_bytes = csv_buffer.getvalue().encode(\"utf-8\")\n",
    "        existing_files = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in existing_files and any(f['Key'] == file_name for f in existing_files['Contents']):\n",
    "            s3_client.delete_object(Bucket=bucket_name, Key=file_name)\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=file_name,\n",
    "            Body=file_bytes,\n",
    "            ContentType=\"text/csv\"\n",
    "        )\n",
    "        print(f\"Fichier '{file_name}' uploadé dans '{bucket_name}'\")\n",
    "    except Exception as ex:\n",
    "        print(\"Erreur upload S3 :\", ex)\n",
    "\n",
    "def load_model_from_s3(file_name=\"modele_epoch4000.pkl\", bucket_name=\"dlhybride\"):##################################################\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pkl\") as tmp_file:\n",
    "            tmp_file.write(response[\"Body\"].read())\n",
    "            tmp_model_path = tmp_file.name\n",
    "        model_loaded = joblib.load(tmp_model_path)\n",
    "        print(f\"Modèle '{file_name}' chargé depuis S3 :\", type(model_loaded))\n",
    "        return model_loaded\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur chargement modèle '{file_name}' :\", e)\n",
    "\n",
    "def load_fake_profiles_from_s3(file_name=\"fake_profiles.csv\", bucket_name=\"dlhybride\"):\n",
    "    try:\n",
    "        existing_files = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if \"Contents\" not in existing_files or not any(f[\"Key\"] == file_name for f in existing_files[\"Contents\"]):\n",
    "            print(f\"Le fichier '{file_name}' n'existe pas dans '{bucket_name}'\")\n",
    "            return None\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "        df = pd.read_csv(io.BytesIO(response[\"Body\"].read()), dtype=str)\n",
    "        if \"skill_code\" in df.columns:\n",
    "            df[\"skill_code\"] = df[\"skill_code\"].str.strip()\n",
    "        print(f\"Fichier '{file_name}' chargé et nettoyé depuis '{bucket_name}'\")\n",
    "        return df\n",
    "    except Exception as ex:\n",
    "        print(\"Erreur lecture S3 :\", ex)\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Chargement des données métiers / compétences\n",
    "# ---------------------------\n",
    "df_jobs = read_csv_from_s3(\"df_competence_rome_eda_v2.csv\")\n",
    "if df_jobs is None:\n",
    "    raise FileNotFoundError(\"Impossible de charger df_competence_rome_eda_v2.csv depuis S3\")\n",
    "\n",
    "df_jobs['code_ogr_competence'] = df_jobs['code_ogr_competence'].astype(str).str.strip()\n",
    "\n",
    "skills_vocab = {code: idx for idx, code in enumerate(df_jobs['code_ogr_competence'].unique())}\n",
    "skill_to_label = df_jobs.drop_duplicates('code_ogr_competence') \\\n",
    "    .set_index('code_ogr_competence')['libelle_competence'].to_dict()\n",
    "jobs_vocab = {rome: idx for idx, rome in enumerate(df_jobs['code_rome'].unique())}\n",
    "job_labels = df_jobs.drop_duplicates('code_rome').set_index('code_rome')['libelle_rome'].to_dict()\n",
    "job_to_skills = df_jobs.groupby('code_rome')['code_ogr_competence'].apply(set).to_dict()\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Génération de faux profils\n",
    "# ---------------------------\n",
    "def generate_fake_profile(job_code, min_ratio=0.5, max_ratio=0.9):\n",
    "    skills = list(job_to_skills[job_code])\n",
    "    keep_ratio = random.uniform(min_ratio, max_ratio)\n",
    "    n_keep = max(1, int(len(skills) * keep_ratio))\n",
    "    return random.sample(skills, n_keep)\n",
    "\n",
    "fake_profiles_list = []\n",
    "for _ in range(2):\n",
    "    job = random.choice(list(job_to_skills.keys()))\n",
    "    selected_skills = generate_fake_profile(job)\n",
    "    fake_profiles_list.append({\n",
    "        \"job_code\": job,\n",
    "        \"job_label\": job_labels.get(job, \"?\"),\n",
    "        \"skills\": selected_skills,\n",
    "        \"skills_labels\": [skill_to_label.get(s, \"?\") for s in selected_skills]\n",
    "    })\n",
    "\n",
    "rows = []\n",
    "for i, profile in enumerate(fake_profiles_list, 1):\n",
    "    for skill, label in zip(profile[\"skills\"], profile[\"skills_labels\"]):\n",
    "        rows.append({\n",
    "            \"profile_id\": i,\n",
    "            \"job_code\": profile[\"job_code\"],\n",
    "            \"job_label\": profile[\"job_label\"],\n",
    "            \"skill_code\": skill,\n",
    "            \"skill_label\": label\n",
    "        })\n",
    "df_profiles = pd.DataFrame(rows)\n",
    "upload_df_to_s3(df_profiles, \"fake_profiles.csv\")\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Chargement du modèle et des faux profils\n",
    "# ---------------------------\n",
    "model_loaded = load_model_from_s3(\"modele_epoch4000.pkl\")#####################################\n",
    "fake_profiles = load_fake_profiles_from_s3(\"fake_profiles.csv\")\n",
    "if fake_profiles is None:\n",
    "    raise FileNotFoundError(\"Impossible de charger fake_profiles.csv depuis S3\")\n",
    "\n",
    "skills_vocab_clean = {k.strip(): v for k, v in skills_vocab.items()}\n",
    "\n",
    "# ---------------------------\n",
    "# 8. Fonction de prédiction hybride\n",
    "# ---------------------------\n",
    "def predict_hybrid(model, input_skills, skills_vocab, job_to_skills, jobs_vocab, job_labels, top_k=3, seuil=0.3, min_overlap=2):\n",
    "    device = next(model.parameters()).device\n",
    "    ids = [skills_vocab[s] for s in input_skills if s in skills_vocab]\n",
    "    if len(ids) == 0:\n",
    "        return \"Indéfini (aucune compétence reconnue)\"\n",
    "    \n",
    "    skills_tensor = torch.tensor(ids).unsqueeze(0).to(device)\n",
    "    weights = torch.tensor([1.0]*len(ids), dtype=torch.float).unsqueeze(0).to(device)\n",
    "    v_p = model.encode_profile(skills_tensor, weights)\n",
    "    all_jobs = torch.arange(len(jobs_vocab)).to(device)\n",
    "    v_j = model.encode_job(all_jobs)\n",
    "    \n",
    "    # Similarité DL\n",
    "    scores_dl = (v_p @ v_j.T).squeeze(0)\n",
    "    \n",
    "    # Heuristique overlap\n",
    "    input_set = set(input_skills)\n",
    "    overlap_scores_list = [len(input_set & job_to_skills.get(j, set())) for j in jobs_vocab.keys()]\n",
    "    overlap_scores = torch.tensor(overlap_scores_list, device=device)\n",
    "    \n",
    "    combined_scores = 0.3*scores_dl + 0.7*(overlap_scores / max(1, max(overlap_scores)))\n",
    "    \n",
    "    mask = overlap_scores >= min_overlap\n",
    "    filtered_indices = torch.arange(len(jobs_vocab), device=device)[mask]\n",
    "    filtered_scores = combined_scores[mask]\n",
    "    \n",
    "    if len(filtered_scores) == 0:\n",
    "        return \"Indéfini (aucune compétence ne passe le filtre)\"\n",
    "    \n",
    "    best_scores, best_idx = filtered_scores.topk(min(top_k, len(filtered_scores)))\n",
    "    best_jobs = [list(jobs_vocab.keys())[i] for i in filtered_indices[best_idx]]\n",
    "    \n",
    "    lines = []\n",
    "    for rome, s in zip(best_jobs, best_scores):\n",
    "        libelle = job_labels.get(rome, \"?\")\n",
    "        lines.append(f\"{rome} - {libelle} - {round(float(s.detach().cpu())*100,1)}%\")\n",
    "    \n",
    "    if best_scores[0] < seuil:\n",
    "        return \"Indéfini\\n\" + \"\\n\".join(lines)\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "'''\n",
    "# ---------------------------\n",
    "# 9. Boucle de prédiction sur les profils\n",
    "# ---------------------------\n",
    "for profile_id in fake_profiles['profile_id'].unique():\n",
    "    subset = fake_profiles[fake_profiles['profile_id'] == profile_id]\n",
    "    user_skills = subset['skill_code'].tolist()\n",
    "    expected_job = subset['job_code'].iloc[0] if 'job_code' in subset.columns else None\n",
    "    \n",
    "    recognized_skills = [s for s in user_skills if s in skills_vocab_clean]\n",
    "    unrecognized_skills = [s for s in user_skills if s not in skills_vocab_clean]\n",
    "    user_skills_named = [f\"{c} - {skill_to_label.get(c,'?')}\" for c in recognized_skills]\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"Profil {profile_id} → compétences ({len(user_skills)}):\")\n",
    "    for s in user_skills_named:\n",
    "        print(f\" • {s}\")\n",
    "    if unrecognized_skills:\n",
    "        print(f\"Compétences non reconnues ({len(unrecognized_skills)}): {unrecognized_skills}\")\n",
    "    if expected_job:\n",
    "        print(f\"\\nMétier attendu : {expected_job} - {job_labels.get(expected_job,'?')}\")\n",
    "    print(\"\\nTop-3 métiers proposés :\")\n",
    "    \n",
    "    try:\n",
    "        prediction = predict_hybrid(\n",
    "            model_loaded, recognized_skills, skills_vocab_clean,\n",
    "            job_to_skills, jobs_vocab, job_labels, top_k=3\n",
    "        )\n",
    "        print(prediction)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la prédiction : {e}\")\n",
    "\n",
    "print(\"\\nPrédictions terminées\\n\")\n",
    "'''\n",
    "# ---------------------------\n",
    "# 9. Boucle de prédiction sur les profils\n",
    "# ---------------------------\n",
    "for profile_id in fake_profiles['profile_id'].unique():\n",
    "    subset = fake_profiles[fake_profiles['profile_id'] == profile_id]\n",
    "    user_skills = subset['skill_code'].tolist()\n",
    "    expected_job = subset['job_code'].iloc[0] if 'job_code' in subset.columns else None\n",
    "    \n",
    "    recognized_skills = [s for s in user_skills if s in skills_vocab_clean]\n",
    "    unrecognized_skills = [s for s in user_skills if s not in skills_vocab_clean]\n",
    "    user_skills_named = [f\"{c} - {skill_to_label.get(c,'?')}\" for c in recognized_skills]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"Profil {profile_id} → compétences ({len(user_skills)}):\")\n",
    "    for s in user_skills_named:\n",
    "        print(f\" • {s}\")\n",
    "    if unrecognized_skills:\n",
    "        print(f\"Compétences non reconnues ({len(unrecognized_skills)}): {unrecognized_skills}\")\n",
    "    if expected_job:\n",
    "        print(f\"\\nMétier attendu : {expected_job} - {job_labels.get(expected_job,'?')}\")\n",
    "\n",
    "    print(\"\\nTop-3 métiers proposés :\")\n",
    "    \n",
    "    try:\n",
    "        prediction = predict_hybrid(\n",
    "            model_loaded, recognized_skills, skills_vocab_clean,\n",
    "            job_to_skills, jobs_vocab, job_labels, top_k=3\n",
    "        )\n",
    "\n",
    "        # Séparer en lignes si c'est une seule chaîne\n",
    "        if isinstance(prediction, str):\n",
    "            prediction_lines = prediction.strip().split(\"\\n\")\n",
    "        else:\n",
    "            prediction_lines = prediction\n",
    "\n",
    "        for line in prediction_lines:\n",
    "            if not line.strip():\n",
    "                continue  # ignorer lignes vides\n",
    "            job_code = line.split(\" - \")[0].strip()\n",
    "            job_skills = job_to_skills.get(job_code, set())\n",
    "            common_skills = set(recognized_skills) & set(job_skills)\n",
    "\n",
    "            print(f\"{line} | corrélation = {len(common_skills)} compétences\")\n",
    "            if common_skills:\n",
    "                common_named = [f\"{c} - {skill_to_label.get(c, '?')}\" for c in common_skills]\n",
    "                print(\"   Compétences en commun :\")\n",
    "                for cs in sorted(common_named):\n",
    "                    print(f\"     • {cs}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la prédiction : {e}\")\n",
    "\n",
    "print(\"\\nPrédictions terminées\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
