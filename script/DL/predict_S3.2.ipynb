{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a3ec85",
   "metadata": {},
   "source": [
    "Model sans faux profils mais qui va chercher dans une table supabase factice....compétence mise manuellement pour test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51713734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées\n",
      "Modèle 'modele_final_test.pkl' chargé depuis S3\n",
      "==================================================\n",
      "Compétences utilisateur 123 (5 au total) :\n",
      "   • 100023 - Abattre un arbre\n",
      "   • 118788 - Planifier des opérations de chantier\n",
      "   • 483361 - Maintenir la propreté du véhicule\n",
      "   • 122698 - Recenser les arbres à abattre ou à élaguer\n",
      "   • 122575 - Déterminer l'abattage ou l'élagage selon la trajectoire de chute des arbres en prenant en compte l'environnement et les conditions climatiques\n",
      "\n",
      "Top-3 métiers proposés :\n",
      "A1102 - Conducteur / Conductrice d'engins d'exploitation forestière - 72.1%\n",
      "A1201 - Bûcheron / Bûcheronne - 44.1%\n",
      "A1209 - Elagueur / Elagueuse - 28.4%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1. Importation des bibliothèques\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import io\n",
    "import tempfile\n",
    "import joblib\n",
    "import psycopg2  # Pour se connecter à Supabase Postgres\n",
    "print(\"Bibliothèques importées\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Charger variables d'environnement\n",
    "# ---------------------------\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Variables Supabase / S3\n",
    "S3_ENDPOINT_URL = os.getenv(\"S3_ENDPOINT_URL\")\n",
    "S3_ACCESS_KEY_ID = os.getenv(\"S3_ACCESS_KEY_ID\")\n",
    "S3_SECRET_ACCESS_KEY = os.getenv(\"S3_SECRET_ACCESS_KEY\")\n",
    "S3_REGION = os.getenv(\"S3_REGION\")\n",
    "S3_BUCKET = \"dlhybride\"\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Connexion S3 (Supabase Storage)\n",
    "# ---------------------------\n",
    "s3_client = boto3.client(\n",
    "    service_name='s3',\n",
    "    region_name=S3_REGION,\n",
    "    endpoint_url=S3_ENDPOINT_URL,\n",
    "    aws_access_key_id=S3_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=S3_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Charger CSV df_competence_rome_eda_v2 depuis S3\n",
    "# ---------------------------\n",
    "def load_csv_from_s3(file_name, bucket_name=S3_BUCKET):\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    df = pd.read_csv(io.BytesIO(response[\"Body\"].read()), dtype=str)\n",
    "    return df\n",
    "\n",
    "df_jobs = load_csv_from_s3(\"df_competence_rome_eda_v2.csv\")\n",
    "df_jobs[\"code_ogr_competence\"] = df_jobs[\"code_ogr_competence\"].astype(str)\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Construction des mappings\n",
    "# ---------------------------\n",
    "skills_vocab = {code: idx for idx, code in enumerate(df_jobs['code_ogr_competence'].unique())}\n",
    "skill_to_label = df_jobs.drop_duplicates('code_ogr_competence') \\\n",
    "                        .set_index('code_ogr_competence')['libelle_competence'].to_dict()\n",
    "jobs_vocab = {rome: idx for idx, rome in enumerate(df_jobs['code_rome'].unique())}\n",
    "job_labels = df_jobs.drop_duplicates('code_rome').set_index('code_rome')['libelle_rome'].to_dict()\n",
    "job_to_skills = df_jobs.groupby('code_rome')['code_ogr_competence'].apply(set).to_dict()\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Charger le modèle depuis S3\n",
    "# ---------------------------\n",
    "def load_model_from_s3(file_name=\"modele_final_test.pkl\", bucket_name=S3_BUCKET):\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    model_bytes = response[\"Body\"].read()\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pkl\") as tmp_file:\n",
    "        tmp_file.write(model_bytes)\n",
    "        tmp_model_path = tmp_file.name\n",
    "    model_loaded = joblib.load(tmp_model_path)\n",
    "    print(f\"Modèle '{file_name}' chargé depuis S3\")\n",
    "    return model_loaded\n",
    "\n",
    "model_loaded = load_model_from_s3()\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Fonction pour récupérer les compétences d'un utilisateur depuis Supabase\n",
    "# ---------------------------\n",
    "def get_user_skills(user_id):\n",
    "    \"\"\"\n",
    "    Récupère les compétences associées à un utilisateur depuis la table 'utilisateur'.\n",
    "    \"\"\"\n",
    "    # Connexion à la base Supabase Postgres\n",
    "    conn = psycopg2.connect(\n",
    "        host=os.getenv(\"SUPABASE_HOST\"),\n",
    "        dbname=os.getenv(\"SUPABASE_DB\"),\n",
    "        user=os.getenv(\"SUPABASE_USER\"),\n",
    "        password=os.getenv(\"SUPABASE_PASSWORD\"),\n",
    "        port=os.getenv(\"SUPABASE_PORT\", 5432)\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    # Exemple : on suppose que la table a des colonnes user_id et skill_code\n",
    "    cur.execute(\"SELECT skill_code FROM utilisateur WHERE user_id = %s\", (user_id,))\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return [r[0] for r in rows]\n",
    "\n",
    "# ---------------------------\n",
    "# 8. Fonction de prédiction hybride\n",
    "# ---------------------------\n",
    "def predict_hybrid(model, input_skills, skills_vocab, job_to_skills, jobs_vocab, job_labels,\n",
    "                   top_k=3, seuil=0.3, min_overlap=2):\n",
    "    device = next(model.parameters()).device\n",
    "    ids = [skills_vocab[s] for s in input_skills if s in skills_vocab]\n",
    "    if len(ids) == 0:\n",
    "        return \"Indéfini (aucune compétence reconnue)\"\n",
    "    skills = torch.tensor(ids).unsqueeze(0).to(device)\n",
    "    weights = torch.tensor([1.0 for _ in ids], dtype=torch.float).unsqueeze(0).to(device)\n",
    "    v_p = model.encode_profile(skills, weights)\n",
    "    all_jobs = torch.arange(len(jobs_vocab)).to(device)\n",
    "    v_j = model.encode_job(all_jobs)\n",
    "    scores_dl = (v_p @ v_j.T).squeeze(0)\n",
    "    input_set = set(input_skills)\n",
    "    overlap_scores_list = [len(input_set & set(job_to_skills.get(j, []))) for j in jobs_vocab.keys()]\n",
    "    overlap_scores = torch.tensor(overlap_scores_list, device=device)\n",
    "    combined_scores = 0.3 * scores_dl + 0.7 * (overlap_scores / max(1, max(overlap_scores)))\n",
    "    filtered_indices = torch.arange(len(jobs_vocab), device=device)[overlap_scores >= min_overlap]\n",
    "    filtered_scores = combined_scores[overlap_scores >= min_overlap]\n",
    "    if len(filtered_scores) == 0:\n",
    "        return \"Indéfini (aucune compétence ne passe le filtre)\"\n",
    "    best_scores, best_idx = filtered_scores.topk(min(top_k, len(filtered_scores)))\n",
    "    best_jobs = [list(jobs_vocab.keys())[i] for i in filtered_indices[best_idx]]\n",
    "    lines = []\n",
    "    for rome, s in zip(best_jobs, best_scores):\n",
    "        libelle = job_labels.get(rome, \"?\")\n",
    "        lines.append(f\"{rome} - {libelle} - {round(float(s.detach().cpu())*100,1)}%\")\n",
    "    if best_scores[0] < seuil:\n",
    "        return \"Indéfini\\n\" + \"\\n\".join(lines)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ---------------------------\n",
    "# 9. Exemple d'utilisation avec affichage détaillé des compétences\n",
    "# ---------------------------\n",
    "user_id = 123  # ID d'utilisateur réel dans la table Supabase\n",
    "user_skills = [\"100023\",\"118788\",\"483361\",\"122698\",\"122575\"]#get_user_skills(user_id)\n",
    "\n",
    "# Séparer les compétences reconnues et non reconnues\n",
    "recognized_skills = [s for s in user_skills if s in skills_vocab]\n",
    "unrecognized_skills = [s for s in user_skills if s not in skills_vocab]\n",
    "\n",
    "# Préparer l'affichage avec libellé\n",
    "recognized_skills_named = [f\"{s} - {skill_to_label.get(s, '?')}\" for s in recognized_skills]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"Compétences utilisateur {user_id} ({len(user_skills)} au total) :\")\n",
    "for s in recognized_skills_named:\n",
    "    print(f\"   • {s}\")\n",
    "\n",
    "if unrecognized_skills:\n",
    "    print(f\"\\nCompétences non reconnues ({len(unrecognized_skills)}) : {unrecognized_skills}\")\n",
    "\n",
    "# Prédiction des métiers\n",
    "print(\"\\nTop-3 métiers proposés :\")\n",
    "prediction = predict_hybrid(\n",
    "    model_loaded,\n",
    "    recognized_skills,\n",
    "    skills_vocab,\n",
    "    job_to_skills,\n",
    "    jobs_vocab,\n",
    "    job_labels,\n",
    "    top_k=3\n",
    ")\n",
    "print(prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d326af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
